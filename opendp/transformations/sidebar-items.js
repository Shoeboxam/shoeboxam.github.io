window.SIDEBAR_ITEMS = {"fn":[["choose_branching_factor","Returns an approximation to the ideal `branching_factor` for a dataset of a given size,  that minimizes error in cdf and quantile estimates based on b-ary trees."],["make_b_ary_tree","Expand a vector of counts into a b-ary tree of counts,  where each branch is the sum of its `b` immediate children."],["make_bounded_float_checked_sum","Make a Transformation that computes the sum of bounded data with known dataset size. "],["make_bounded_float_ordered_sum","Make a Transformation that computes the sum of bounded floats. "],["make_bounded_int_monotonic_sum","Make a Transformation that computes the sum of bounded ints,  where all values share the same sign."],["make_bounded_int_ordered_sum","Make a Transformation that computes the sum of bounded ints. You may need to use `make_ordered_random` to impose an ordering on the data."],["make_bounded_int_split_sum","Make a Transformation that computes the sum of bounded ints.  Adds the saturating sum of the positives to the saturating sum of the negatives."],["make_bounded_sum","Make a Transformation that computes the sum of bounded data.  Use `make_clamp` to bound data."],["make_cast","Make a Transformation that casts a vector of data from type `TIA` to type `TOA`. Failure to parse results in None, else Some."],["make_cast_default","Make a Transformation that casts a vector of data from type `TIA` to type `TOA`.  If the cast fails, fill with default."],["make_cast_inherent","Make a Transformation that casts a vector of data from type `TI` to a type that can represent nullity `TO`.  If cast fails, fill with `TO`â€™s null value."],["make_cdf","Postprocess a noisy array of float summary counts into a cumulative distribution."],["make_clamp","Make a Transformation that clamps numeric data in Vec<`T`> to `bounds`. If datum is less than lower, let datum be lower.  If datum is greater than upper, let datum be upper."],["make_consistent_b_ary_tree","Postprocessing transformation that makes a noisy b-ary tree internally consistent, and returns the leaf layer."],["make_count","Make a Transformation that computes a count of the number of records in data."],["make_count_by","Make a Transformation that computes the count of each unique value in data.  This assumes that the category set is unknown."],["make_count_by_categories","Make a Transformation that computes the number of times each category appears in the data.  This assumes that the category set is known."],["make_count_distinct","Make a Transformation that computes a count of the number of unique, distinct records in data."],["make_create_dataframe","Make a Transformation that constructs a dataframe from a `Vec<Vec<String>>` (a vector of records)."],["make_df_cast_default","Make a Transformation that casts the elements in a column in a dataframe from type `TIA` to type `TOA`.  If cast fails, fill with default."],["make_df_is_equal","Make a Transformation that checks if each element in a column in a dataframe is equivalent to `value`"],["make_drop_null","Make a Transformation that drops null values. `DA` is one of `OptionNullDomain<AllDomain<TA>>` or `InherentNullDomain<AllDomain<TA>>`."],["make_find","Find the index of a data value in a set of categories."],["make_find_bin","Make a transformation that finds the bin index in a monotonically increasing vector of edges."],["make_identity","Constructs a [`Transformation`] representing the identity function."],["make_impute_constant","Make a Transformation that replaces null/None data with `constant`."],["make_impute_uniform_float","Make a Transformation that replaces NaN values in Vec<`TA`> with uniformly distributed floats within `bounds`."],["make_index","Make a transformation that treats each element as an index into a vector of categories."],["make_is_equal","Make a Transformation that checks if each element is equal to `value`."],["make_is_null","Make a Transformation that checks if each element in a vector is null."],["make_lipschitz_float_mul","Make a transformation that multiplies an aggregate by a constant."],["make_metric_bounded","Make a Transformation that converts the unbounded dataset metric `MI`  to the respective bounded dataset metric with a no-op. "],["make_metric_unbounded","Make a Transformation that converts the bounded dataset metric `MI`  to the respective unbounded dataset metric with a no-op. "],["make_ordered_random","Make a Transformation that converts the unordered dataset metric `SymmetricDistance` to the respective ordered dataset metric `InsertDeleteDistance` by assigning a random permutatation."],["make_quantiles_from_counts","Postprocess a noisy array of summary counts into quantiles."],["make_resize","Make a Transformation that either truncates or imputes records  with `constant` to match a provided `size`."],["make_select_column","Make a Transformation that retrieves the column `key` from a dataframe as Vec<`TOA`>."],["make_sized_bounded_covariance",""],["make_sized_bounded_float_checked_sum","Make a Transformation that computes the sum of bounded floats with known dataset size. "],["make_sized_bounded_float_ordered_sum","Make a Transformation that computes the sum of bounded floats with known dataset size. "],["make_sized_bounded_int_checked_sum","Make a Transformation that computes the sum of bounded ints.  The effective range is reduced, as (bounds * size) must not overflow."],["make_sized_bounded_int_monotonic_sum","Make a Transformation that computes the sum of bounded ints,  where all values share the same sign."],["make_sized_bounded_int_ordered_sum","Make a Transformation that computes the sum of bounded ints with known dataset size. "],["make_sized_bounded_int_split_sum","Make a Transformation that computes the sum of bounded ints with known dataset size. "],["make_sized_bounded_mean","Make a Transformation that computes the mean of bounded data."],["make_sized_bounded_sum","Make a Transformation that computes the sum of bounded data with known dataset size. "],["make_sized_bounded_sum_of_squared_deviations","Make a Transformation that computes the sum of squared deviations of bounded data. "],["make_sized_bounded_variance","Make a Transformation that computes the variance of bounded data. "],["make_split_dataframe","Make a Transformation that splits each record in a String into a `Vec<Vec<String>>`, and loads the resulting table into a dataframe keyed by `col_names`."],["make_split_lines","Make a Transformation that takes a string and splits it into a `Vec<String>` of its lines."],["make_split_records","Make a Transformation that splits each record in a `Vec<String>` into a `Vec<Vec<String>>`."],["make_subset_by","Make a Transformation that subsets a dataframe by a boolean column."],["make_unclamp","Make a Transformation that unclamps numeric data in Vec<`T`>."],["make_unordered","Make a Transformation that converts the ordered dataset metric `InsertDeleteDistance` to the respective ordered dataset metric SymmetricDistance with a no-op."]],"struct":[["Pairwise","Marker type to represent pairwise, or cascading summation"],["Sequential","Marker type to represent sequential, or recursive summation"]],"trait":[["BAryTreeMetric",""],["DropNullDomain","Utility trait to drop null values from a dataset, regardless of the representation of nullity."],["ImputeConstantDomain","Utility trait to impute with a constant, regardless of the representation of nullity."],["LipschitzMulFloatDomain","Implemented for any domain that supports multiplication lipschitz extensions"],["LipschitzMulFloatMetric","Implemented for any metric that supports multiplication lipschitz extensions"]],"type":[["DataFrame",""],["DataFrameDomain",""]]};